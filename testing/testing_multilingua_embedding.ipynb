{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joaopn/software/miniconda3/envs/ranker/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lexicalrichness import LexicalRichness\n",
    "from detoxify import Detoxify\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import fasttext\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarizationAnalyzer():\n",
    "    def __init__(self,model = 'sentence-transformers/all-mpnet-base-v2'):\n",
    "        # Initialize the model\n",
    "        self.model = SentenceTransformer(model, device=\"cuda\")\n",
    "        self.batch_size = 1024\n",
    "        # Load the polarization terms and compute their embeddings\n",
    "        self.load_and_embed_terms()\n",
    "\n",
    "    def load_and_embed_terms(self):\n",
    "        # Load terms from CSV\n",
    "        filepath = \"civirank/data/polarization_dictionary.csv\"\n",
    "        df = pd.read_csv(filepath, header=0)\n",
    "        df = df[df['label'] == 'issue']\n",
    "        unique_words = df['word'].unique()\n",
    "        \n",
    "        # Compute embeddings for the unique words\n",
    "        self.dict_embeddings = self.model.encode(\n",
    "            list(unique_words),\n",
    "            batch_size=self.batch_size,\n",
    "            show_progress_bar=False,\n",
    "            convert_to_tensor=True\n",
    "        )\n",
    "        \n",
    "        # Average the embeddings to create a single dictionary embedding\n",
    "        self.dict_embeddings = torch.mean(self.dict_embeddings, dim=0)\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        # Regular expressions to clean up the text data\n",
    "        df[\"text\"] = df[\"text\"].replace(\n",
    "            to_replace=[r\"(?:https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})\"],\n",
    "            value=[\"\"], \n",
    "            regex=True,\n",
    "        )\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"&.*;\", value=\"\", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True) \n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\s+\", value=\" \", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\@\\w+\", value=\"@user\", regex=True)\n",
    "\n",
    "    def get_embeddings(self, df):\n",
    "        # Encode text in batches\n",
    "        corpus_embeddings = self.model.encode(\n",
    "            list(df[\"text\"]),\n",
    "            batch_size=1024,\n",
    "            show_progress_bar=False, \n",
    "            convert_to_tensor=True\n",
    "        ) \n",
    "\n",
    "        assert len(corpus_embeddings) == len(df)\n",
    "        return corpus_embeddings\n",
    "    \n",
    "    def compute_similarity(self, text_embeddings):\n",
    "        # Calculate cosine similarity between text embeddings and dictionary embeddings\n",
    "        cos_sim = util.cos_sim(text_embeddings, self.dict_embeddings)\n",
    "        return cos_sim\n",
    "    \n",
    "    def get_similarity(self, texts):\n",
    "        df = texts.copy()\n",
    "        self.preprocess(df)\n",
    "        text_embeddings = self.get_embeddings(df)\n",
    "        cos_sim = self.compute_similarity(text_embeddings)\n",
    "        return cos_sim.cpu().numpy()\n",
    "\n",
    "class PolarizationAnalyzerGlove():\n",
    "    def __init__(self):\n",
    "        # Initialize the model\n",
    "        model_path = \"civirank/data/glove-model-reduced-stopwords\"\n",
    "        self.model = SentenceTransformer(model_path, device=\"cuda\")\n",
    "        self.batch_size = 1024\n",
    "        # Load the polarization terms and compute their embeddings\n",
    "        self.load_and_embed_terms()\n",
    "\n",
    "    def load_and_embed_terms(self):\n",
    "        # Load terms from CSV\n",
    "        pkl_path = \"civirank/data/issue_polarization_embeddings.pkl\"\n",
    "        with open(pkl_path, \"rb\") as fin:\n",
    "            self.dict_embeddings = pickle.load(fin)[\"embeddings\"].to(\"cuda\")\n",
    "            self.dict_embeddings = torch.mean(self.dict_embeddings, dim=0)\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        # Regular expressions to clean up the text data\n",
    "        df[\"text\"] = df[\"text\"].replace(\n",
    "            to_replace=[r\"(?:https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})\"],\n",
    "            value=[\"\"], \n",
    "            regex=True,\n",
    "        )\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"&.*;\", value=\"\", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True) \n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\s+\", value=\" \", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\@\\w+\", value=\"@user\", regex=True)\n",
    "\n",
    "    def get_embeddings(self, df):\n",
    "        # Encode text in batches\n",
    "        corpus_embeddings = self.model.encode(\n",
    "            list(df[\"text\"]),\n",
    "            batch_size=1024,\n",
    "            show_progress_bar=False, \n",
    "            convert_to_tensor=True\n",
    "        ) \n",
    "\n",
    "        assert len(corpus_embeddings) == len(df)\n",
    "        return corpus_embeddings\n",
    "    \n",
    "    def compute_similarity(self, text_embeddings):\n",
    "        # Calculate cosine similarity between text embeddings and dictionary embeddings\n",
    "        cos_sim = util.cos_sim(text_embeddings, self.dict_embeddings)\n",
    "        return cos_sim\n",
    "    \n",
    "    def get_similarity(self, texts):\n",
    "        df = texts.copy()\n",
    "        self.preprocess(df)\n",
    "        text_embeddings = self.get_embeddings(df)\n",
    "        cos_sim = self.compute_similarity(text_embeddings)\n",
    "        return cos_sim.cpu().numpy()\n",
    "\n",
    "def compute_similarities(sentences_dict, analyzer):\n",
    "    results = {}\n",
    "    for language, texts in sentences_dict.items():\n",
    "        similarities = analyzer.get_similarity(pd.DataFrame({\"text\": texts}))\n",
    "        results[language] = similarities.flatten().tolist()\n",
    "    df = pd.DataFrame(results, index=['polarized1', 'polarized2', 'unpolarized1', 'unpolarized2'])\n",
    "    return df\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PolarizationAnalyzerTF():\n",
    "    def __init__(self, model='sentence-transformers/all-mpnet-base-v2'):\n",
    "        # Initialize the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.model = AutoModel.from_pretrained(model)\n",
    "        self.batch_size = 1024\n",
    "        # Load the polarization terms and compute their embeddings\n",
    "        self.load_and_embed_terms()\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def load_and_embed_terms(self):\n",
    "        # Load terms from CSV\n",
    "        filepath = \"civirank/data/polarization_dictionary.csv\"\n",
    "        df = pd.read_csv(filepath, header=0)\n",
    "        df = df[df['label'] == 'issue']\n",
    "        unique_words = df['word'].unique()\n",
    "        \n",
    "        # Tokenize terms\n",
    "        encoded_input = self.tokenizer(list(unique_words), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "\n",
    "        # Perform pooling\n",
    "        term_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        # Average the embeddings to create a single dictionary embedding\n",
    "        self.dict_embeddings = torch.mean(term_embeddings, dim=0)\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        # Regular expressions to clean up the text data\n",
    "        df[\"text\"] = df[\"text\"].replace(\n",
    "            to_replace=[r\"(?:https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,})\"],\n",
    "            value=[\"\"], \n",
    "            regex=True,\n",
    "        )\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"&.*;\", value=\"\", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=[r\"\\\\t|\\\\n|\\\\r\", \"\\t|\\n|\\r\"], value=[\"\",\"\"], regex=True) \n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\s+\", value=\" \", regex=True)\n",
    "        df[\"text\"] = df[\"text\"].replace(to_replace=r\"\\@\\w+\", value=\"@user\", regex=True)\n",
    "\n",
    "    def get_embeddings(self, df):\n",
    "        # Encode text in batches\n",
    "        encoded_input = self.tokenizer(list(df[\"text\"]), padding=True, truncation=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "        text_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        return text_embeddings\n",
    "    \n",
    "    def compute_similarity(self, text_embeddings):\n",
    "        # Calculate cosine similarity between text embeddings and dictionary embeddings\n",
    "        cos_sim = util.cos_sim(text_embeddings, self.dict_embeddings)\n",
    "        return cos_sim\n",
    "    \n",
    "    def get_similarity(self, texts):\n",
    "        df = texts.copy()\n",
    "        self.preprocess(df)\n",
    "        text_embeddings = self.get_embeddings(df)\n",
    "        cos_sim = self.compute_similarity(text_embeddings)\n",
    "        return cos_sim.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accommodate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>admire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>affable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>affection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word\n",
       "0  accommodate\n",
       "1       admire\n",
       "2       advise\n",
       "3      affable\n",
       "4    affection"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"civirank/data/prosocial_dictionary.csv\"\n",
    "df = pd.read_csv(filepath, header=None, names = ['word'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of sentences\n",
    "sentences = {\n",
    "    \"English\": [\n",
    "        \"The corrupt politicians are ruining our democracy with their lies and deceit.\",\n",
    "        \"These criminals are a threat to our peaceful society and must be stopped.\",\n",
    "        \"The local community held a meeting to discuss the upcoming elections.\",\n",
    "        \"People from different backgrounds came together to celebrate the festival.\"\n",
    "    ],\n",
    "    \"Italian\": [\n",
    "        \"I politici corrotti stanno rovinando la nostra democrazia con le loro bugie e inganni.\",\n",
    "        \"Questi criminali sono una minaccia per la nostra società pacifica e devono essere fermati.\",\n",
    "        \"La comunità locale ha tenuto una riunione per discutere le prossime elezioni.\",\n",
    "        \"Persone di diversi background si sono riunite per celebrare il festival.\"\n",
    "    ],\n",
    "    \"French\": [\n",
    "        \"Les politiciens corrompus ruinent notre démocratie avec leurs mensonges et tromperies.\",\n",
    "        \"Ces criminels sont une menace pour notre société paisible et doivent être arrêtés.\",\n",
    "        \"La communauté locale a tenu une réunion pour discuter des prochaines élections.\",\n",
    "        \"Des personnes de différents horizons se sont réunies pour célébrer le festival.\"\n",
    "    ],\n",
    "    \"Russian\": [\n",
    "        \"Коррумпированные политики разрушают нашу демократию своими ложью и обманом.\",\n",
    "        \"Эти преступники угрожают нашему мирному обществу и должны быть остановлены.\",\n",
    "        \"Местное сообщество провело встречу для обсуждения предстоящих выборов.\",\n",
    "        \"Люди из разных слоев общества собрались, чтобы отпраздновать фестиваль.\"\n",
    "    ],\n",
    "    \"Portuguese\": [\n",
    "        \"Os políticos corruptos estão arruinando nossa democracia com suas mentiras e enganos.\",\n",
    "        \"Esses criminosos são uma ameaça para nossa sociedade pacífica e devem ser detidos.\",\n",
    "        \"A comunidade local realizou uma reunião para discutir as próximas eleições.\",\n",
    "        \"Pessoas de diferentes origens se reuniram para celebrar o festival.\"\n",
    "    ],\n",
    "    \"Spanish\": [\n",
    "        \"Los políticos corruptos están arruinando nuestra democracia con sus mentiras y engaños.\",\n",
    "        \"Estos criminales son una amenaza para nuestra sociedad pacífica y deben ser detenidos.\",\n",
    "        \"La comunidad local celebró una reunión para discutir las próximas elecciones.\",\n",
    "        \"Personas de diferentes orígenes se reunieron para celebrar el festival.\"\n",
    "    ],\n",
    "    \"Turkish\": [\n",
    "        \"Yolsuz politikacılar yalanları ve aldatmacalarıyla demokrasimizi mahvediyorlar.\",\n",
    "        \"Bu suçlular barışçıl toplumumuza tehdit oluşturuyor ve durdurulmaları gerekiyor.\",\n",
    "        \"Yerel topluluk, yaklaşan seçimleri tartışmak için bir toplantı yaptı.\",\n",
    "        \"Farklı geçmişlerden insanlar festivali kutlamak için bir araya geldi.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.322196</td>\n",
       "      <td>0.260662</td>\n",
       "      <td>0.214817</td>\n",
       "      <td>0.077519</td>\n",
       "      <td>0.238514</td>\n",
       "      <td>0.258684</td>\n",
       "      <td>0.392205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.272224</td>\n",
       "      <td>0.125750</td>\n",
       "      <td>0.190544</td>\n",
       "      <td>0.069050</td>\n",
       "      <td>0.214022</td>\n",
       "      <td>0.205365</td>\n",
       "      <td>0.150611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.277194</td>\n",
       "      <td>0.162375</td>\n",
       "      <td>0.214758</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.261384</td>\n",
       "      <td>0.236920</td>\n",
       "      <td>0.205943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.185894</td>\n",
       "      <td>0.071506</td>\n",
       "      <td>0.019552</td>\n",
       "      <td>0.047946</td>\n",
       "      <td>0.088326</td>\n",
       "      <td>0.125417</td>\n",
       "      <td>0.163404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.322196  0.260662  0.214817  0.077519    0.238514  0.258684   \n",
       "polarized2    0.272224  0.125750  0.190544  0.069050    0.214022  0.205365   \n",
       "unpolarized1  0.277194  0.162375  0.214758  0.061415    0.261384  0.236920   \n",
       "unpolarized2  0.185894  0.071506  0.019552  0.047946    0.088326  0.125417   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.392205  \n",
       "polarized2    0.150611  \n",
       "unpolarized1  0.205943  \n",
       "unpolarized2  0.163404  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF, all-mpnet-base-v2, fixed dict\n",
    "V = PolarizationAnalyzerTF(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joao\\miniconda3\\envs\\ranker311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.322082</td>\n",
       "      <td>0.259304</td>\n",
       "      <td>0.214406</td>\n",
       "      <td>0.077373</td>\n",
       "      <td>0.238186</td>\n",
       "      <td>0.257892</td>\n",
       "      <td>0.390958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.270462</td>\n",
       "      <td>0.123833</td>\n",
       "      <td>0.188338</td>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.212405</td>\n",
       "      <td>0.203302</td>\n",
       "      <td>0.151397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.276402</td>\n",
       "      <td>0.160782</td>\n",
       "      <td>0.214057</td>\n",
       "      <td>0.061325</td>\n",
       "      <td>0.260947</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>0.206550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.185092</td>\n",
       "      <td>0.070614</td>\n",
       "      <td>0.019575</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>0.126057</td>\n",
       "      <td>0.163701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.322082  0.259304  0.214406  0.077373    0.238186  0.257892   \n",
       "polarized2    0.270462  0.123833  0.188338  0.068888    0.212405  0.203302   \n",
       "unpolarized1  0.276402  0.160782  0.214057  0.061325    0.260947  0.236816   \n",
       "unpolarized2  0.185092  0.070614  0.019575  0.048472    0.088947  0.126057   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.390958  \n",
       "polarized2    0.151397  \n",
       "unpolarized1  0.206550  \n",
       "unpolarized2  0.163701  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all-mpnet-base-v2, fixed dict\n",
    "V = PolarizationAnalyzer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joao\\miniconda3\\envs\\ranker311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.306575</td>\n",
       "      <td>0.348605</td>\n",
       "      <td>0.331212</td>\n",
       "      <td>0.334709</td>\n",
       "      <td>0.338811</td>\n",
       "      <td>0.338522</td>\n",
       "      <td>0.362182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.416198</td>\n",
       "      <td>0.418934</td>\n",
       "      <td>0.414645</td>\n",
       "      <td>0.444557</td>\n",
       "      <td>0.419443</td>\n",
       "      <td>0.411341</td>\n",
       "      <td>0.424486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.370046</td>\n",
       "      <td>0.388773</td>\n",
       "      <td>0.392882</td>\n",
       "      <td>0.403784</td>\n",
       "      <td>0.381662</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.407820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.183952</td>\n",
       "      <td>0.202088</td>\n",
       "      <td>0.227249</td>\n",
       "      <td>0.233623</td>\n",
       "      <td>0.217560</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.234870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.306575  0.348605  0.331212  0.334709    0.338811  0.338522   \n",
       "polarized2    0.416198  0.418934  0.414645  0.444557    0.419443  0.411341   \n",
       "unpolarized1  0.370046  0.388773  0.392882  0.403784    0.381662  0.377300   \n",
       "unpolarized2  0.183952  0.202088  0.227249  0.233623    0.217560  0.207749   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.362182  \n",
       "polarized2    0.424486  \n",
       "unpolarized1  0.407820  \n",
       "unpolarized2  0.234870  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence-transformers/paraphrase-multilingual-mpnet-base-v2, fixed dict\n",
    "V = PolarizationAnalyzer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joao\\miniconda3\\envs\\ranker311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.032390</td>\n",
       "      <td>0.138811</td>\n",
       "      <td>0.048786</td>\n",
       "      <td>0.093928</td>\n",
       "      <td>0.051559</td>\n",
       "      <td>0.091762</td>\n",
       "      <td>0.234064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.049420</td>\n",
       "      <td>0.061838</td>\n",
       "      <td>0.051024</td>\n",
       "      <td>0.127765</td>\n",
       "      <td>0.068337</td>\n",
       "      <td>0.101919</td>\n",
       "      <td>0.204548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.089062</td>\n",
       "      <td>0.149770</td>\n",
       "      <td>0.088429</td>\n",
       "      <td>0.102644</td>\n",
       "      <td>0.145071</td>\n",
       "      <td>0.212202</td>\n",
       "      <td>0.223983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.109869</td>\n",
       "      <td>0.107426</td>\n",
       "      <td>0.051646</td>\n",
       "      <td>0.057767</td>\n",
       "      <td>0.107292</td>\n",
       "      <td>0.179788</td>\n",
       "      <td>0.207831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.032390  0.138811  0.048786  0.093928    0.051559  0.091762   \n",
       "polarized2    0.049420  0.061838  0.051024  0.127765    0.068337  0.101919   \n",
       "unpolarized1  0.089062  0.149770  0.088429  0.102644    0.145071  0.212202   \n",
       "unpolarized2  0.109869  0.107426  0.051646  0.057767    0.107292  0.179788   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.234064  \n",
       "polarized2    0.204548  \n",
       "unpolarized1  0.223983  \n",
       "unpolarized2  0.207831  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all-mpnet-base-v2\n",
    "V = PolarizationAnalyzer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Joao\\miniconda3\\envs\\ranker311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.064410</td>\n",
       "      <td>0.093183</td>\n",
       "      <td>0.090366</td>\n",
       "      <td>0.088261</td>\n",
       "      <td>0.083287</td>\n",
       "      <td>0.083460</td>\n",
       "      <td>0.082133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.151675</td>\n",
       "      <td>0.152305</td>\n",
       "      <td>0.158747</td>\n",
       "      <td>0.166214</td>\n",
       "      <td>0.160681</td>\n",
       "      <td>0.154786</td>\n",
       "      <td>0.159406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.171224</td>\n",
       "      <td>0.177547</td>\n",
       "      <td>0.174647</td>\n",
       "      <td>0.182736</td>\n",
       "      <td>0.171821</td>\n",
       "      <td>0.168611</td>\n",
       "      <td>0.186019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.129319</td>\n",
       "      <td>0.146060</td>\n",
       "      <td>0.145040</td>\n",
       "      <td>0.137523</td>\n",
       "      <td>0.145897</td>\n",
       "      <td>0.142713</td>\n",
       "      <td>0.154925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.064410  0.093183  0.090366  0.088261    0.083287  0.083460   \n",
       "polarized2    0.151675  0.152305  0.158747  0.166214    0.160681  0.154786   \n",
       "unpolarized1  0.171224  0.177547  0.174647  0.182736    0.171821  0.168611   \n",
       "unpolarized2  0.129319  0.146060  0.145040  0.137523    0.145897  0.142713   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.082133  \n",
       "polarized2    0.159406  \n",
       "unpolarized1  0.186019  \n",
       "unpolarized2  0.154925  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# paraphrase-multilingual-mpnet-base-v2\n",
    "V = PolarizationAnalyzer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.405083</td>\n",
       "      <td>-0.025230</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>-0.102554</td>\n",
       "      <td>-0.167120</td>\n",
       "      <td>-0.089512</td>\n",
       "      <td>0.130725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.456295</td>\n",
       "      <td>-0.129897</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>-0.102554</td>\n",
       "      <td>-0.114428</td>\n",
       "      <td>-0.099527</td>\n",
       "      <td>0.030498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.416074</td>\n",
       "      <td>-0.096301</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>-0.114010</td>\n",
       "      <td>0.014081</td>\n",
       "      <td>-0.046252</td>\n",
       "      <td>-0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.445963</td>\n",
       "      <td>0.085589</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010606</td>\n",
       "      <td>0.056041</td>\n",
       "      <td>-0.174001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.405083 -0.025230 -0.058530 -0.102554   -0.167120 -0.089512   \n",
       "polarized2    0.456295 -0.129897  0.003199 -0.102554   -0.114428 -0.099527   \n",
       "unpolarized1  0.416074 -0.096301  0.030450 -0.114010    0.014081 -0.046252   \n",
       "unpolarized2  0.445963  0.085589  0.097456  0.000000   -0.010606  0.056041   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.130725  \n",
       "polarized2    0.030498  \n",
       "unpolarized1 -0.047000  \n",
       "unpolarized2 -0.174001  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glove, csv\n",
    "V = PolarizationAnalyzerGlove()\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.612219</td>\n",
       "      <td>0.069996</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.089972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.512247</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.025710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.383135</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.099378</td>\n",
       "      <td>0.131592</td>\n",
       "      <td>0.195840</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.290264</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>0.087840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>0.114827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.612219  0.069996 -0.030130  0.046636    0.052965  0.076015   \n",
       "polarized2    0.512247  0.060953  0.117587  0.046636    0.009452  0.003990   \n",
       "unpolarized1  0.383135  0.095668  0.099378  0.131592    0.195840  0.102686   \n",
       "unpolarized2  0.290264  0.078435  0.087840  0.000000    0.075617  0.051701   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.089972  \n",
       "polarized2    0.025710  \n",
       "unpolarized1  0.119306  \n",
       "unpolarized2  0.114827  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glove, pkl\n",
    "V = PolarizationAnalyzerGlove()\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.612219</td>\n",
       "      <td>0.069996</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.089972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.512247</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.025710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.383135</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.099378</td>\n",
       "      <td>0.131592</td>\n",
       "      <td>0.195840</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.290264</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>0.087840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>0.114827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.612219  0.069996 -0.030130  0.046636    0.052965  0.076015   \n",
       "polarized2    0.512247  0.060953  0.117587  0.046636    0.009452  0.003990   \n",
       "unpolarized1  0.383135  0.095668  0.099378  0.131592    0.195840  0.102686   \n",
       "unpolarized2  0.290264  0.078435  0.087840  0.000000    0.075617  0.051701   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.089972  \n",
       "polarized2    0.025710  \n",
       "unpolarized1  0.119306  \n",
       "unpolarized2  0.114827  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glove, csv\n",
    "V = PolarizationAnalyzer(model='civirank/data/glove-model-reduced-stopwords')\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French</th>\n",
       "      <th>Russian</th>\n",
       "      <th>Portuguese</th>\n",
       "      <th>Spanish</th>\n",
       "      <th>Turkish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>polarized1</th>\n",
       "      <td>0.612219</td>\n",
       "      <td>0.069996</td>\n",
       "      <td>-0.030130</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.052965</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.089972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarized2</th>\n",
       "      <td>0.512247</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>0.117587</td>\n",
       "      <td>0.046636</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.025710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized1</th>\n",
       "      <td>0.383135</td>\n",
       "      <td>0.095668</td>\n",
       "      <td>0.099378</td>\n",
       "      <td>0.131592</td>\n",
       "      <td>0.195840</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unpolarized2</th>\n",
       "      <td>0.290264</td>\n",
       "      <td>0.078435</td>\n",
       "      <td>0.087840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>0.114827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               English   Italian    French   Russian  Portuguese   Spanish  \\\n",
       "polarized1    0.612219  0.069996 -0.030130  0.046636    0.052965  0.076015   \n",
       "polarized2    0.512247  0.060953  0.117587  0.046636    0.009452  0.003990   \n",
       "unpolarized1  0.383135  0.095668  0.099378  0.131592    0.195840  0.102686   \n",
       "unpolarized2  0.290264  0.078435  0.087840  0.000000    0.075617  0.051701   \n",
       "\n",
       "               Turkish  \n",
       "polarized1    0.089972  \n",
       "polarized2    0.025710  \n",
       "unpolarized1  0.119306  \n",
       "unpolarized2  0.114827  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from civirank import analyzers, parsers, rankers\n",
    "# glove codebase, csv\n",
    "V = analyzers.PolarizationAnalyzer()\n",
    "similarity_df = compute_similarities(sentences, V)\n",
    "similarity_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ranker311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
